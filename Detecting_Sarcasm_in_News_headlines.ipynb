{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting Sarcasm in News headlines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOF4+j/VgCipWWcQizKaPPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShashwatVv/DetectingSaracasm-In-NewsHeadlines/blob/main/Detecting_Sarcasm_in_News_headlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Let's first load the dataset. "
      ],
      "metadata": {
        "id": "lRumd9Xv-mQQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYj4fcy9-Tm-",
        "outputId": "9966cd7b-4078-40fc-a2d9-7c799366f374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 10:12:08--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.218.128, 108.177.11.128, 74.125.31.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.218.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-03-28 10:12:08 (218 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##  The libraries to be imported\n",
        "import numpy  as np\n",
        "import json \n",
        "import io\n",
        "import tensorflow  as  tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  as TKN\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences as padseq\n",
        "print(\"Imported!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rol6Vk4Q-sya",
        "outputId": "5500fd1e-3025-4014-ce39-a9cfad9f631c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's load the json-data\n",
        "\n",
        "file_sarc = open('/tmp/sarcasm.json', 'r')\n",
        "data = json.load(file_sarc)\n",
        "file_sarc.close()"
      ],
      "metadata": {
        "id": "WNDXMDMp_xbx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = data[0].keys()\n",
        "print(\"The 3 features associated with the news headlines are:\", *info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vshl8-KgAj6R",
        "outputId": "78316a18-9f6e-4ce5-bd1b-837eb5143dfe"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 3 features associated with the news headlines are: article_link headline is_sarcastic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## let's create separate list of sentences, labels and  links/urls \n",
        "list_of_labels = list() ##sarcastic or non sarcastic\n",
        "list_of_links = list() ##url to the article \n",
        "list_of_sentences = list() \n",
        "\n",
        "for instance in data:\n",
        "  list_of_labels.append(instance['is_sarcastic'])\n",
        "  list_of_links.append(instance['article_link'])\n",
        "  list_of_sentences.append(instance['headline'])\n",
        "\n",
        "print(\"Length of each of these lists are:\",  len(list_of_labels), len(list_of_links), len(list_of_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU8hALWbBARC",
        "outputId": "b8beaace-69a4-4083-eb9c-ba79a36a81c7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of each of these lists are: 26709 26709 26709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's do  some standard preprocessing!!\n",
        "##create  a  tokenizer instance\n",
        "tokenizer_instance = TKN(oov_token = '<OOV>')\n",
        "##let's fit this object on the sentence lists\n",
        "tokenizer_instance.fit_on_texts(list_of_sentences)\n",
        "word_index = tokenizer_instance.word_index"
      ],
      "metadata": {
        "id": "gMGqXlA3CjUo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index\n",
        "list_of_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLnSa53aIERx",
        "outputId": "dedc1a19-1f0c-4262-a2e4-6e67984ec36e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              " \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              " \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              " 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
              " 'j.k. rowling wishes snape happy birthday in the most magical way']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer_instance.texts_to_sequences(list_of_sentences)\n",
        "##this tep was used to ensure tokens represent the words\n",
        "padded = padseq(sequences, padding='post') ##--> 'post' describes all the sequences will be padded to the longest sequence\n",
        "print(padded[0],'\\n', padded.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVVvBcD1IF6h",
        "outputId": "6c47c54f-c814-4281-a924-60370a35bd82"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0] \n",
            " (26709, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Let's set the parameters\n",
        "size_vocab = 10000\n",
        "embedding_dimension = 16\n",
        "len_max = 32\n",
        "truncate = 'post'\n",
        "padding = 'post'\n",
        "ukn_token = '<OOV>'\n",
        "size_train = 20000"
      ],
      "metadata": {
        "id": "IVi1QTIVLrEu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's split into  train and tests!!\n",
        "xtrain, ytrain = list_of_sentences[0:size_train], list_of_labels[0:size_train]\n",
        "xtest,  ytest =  list_of_sentences[size_train:], list_of_labels[size_train:]"
      ],
      "metadata": {
        "id": "jl7sVBv4OnVf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's tokenize and pad  our training and test data\n",
        "\n",
        "tokenizer = TKN(num_words=size_vocab, oov_token=ukn_token)\n",
        "tokenizer.fit_on_texts(xtrain)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(xtrain)\n",
        "train_pad = padseq(train_seq, maxlen=len_max, padding=padding, truncating=truncate)\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(xtest)\n",
        "test_pad = padseq(test_seq, maxlen=len_max, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "1PZ2CB9zPldq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pad = np.array(train_pad)\n",
        "test_pad = np.array(test_pad)\n",
        "ytrain, ytest = np.array(ytrain), np.array(ytest) ##labels"
      ],
      "metadata": {
        "id": "jGpQVLeUjC5i"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Let's  define our model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "  tf.keras.layers.Embedding(size_vocab, embedding_dimension, input_length=len_max),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(24,activation='relu'),\n",
        "  tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "YQa9_9p_fSAH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn7N9FxYj6vW",
        "outputId": "d2472d20-ea2e-4ccb-cf6f-11e187a178e0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 32, 16)            160000    \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                408       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,433\n",
            "Trainable params: 160,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 40\n",
        "history = model.fit(train_pad, ytrain, epochs = n_epoch, validation_data=(test_pad, ytest), verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7wJttyxgp7v",
        "outputId": "82461137-3005-4d6d-8894-8ef0cc2c825a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "625/625 - 3s - loss: 0.5614 - accuracy: 0.7073 - val_loss: 0.3961 - val_accuracy: 0.8369 - 3s/epoch - 5ms/step\n",
            "Epoch 2/40\n",
            "625/625 - 2s - loss: 0.3131 - accuracy: 0.8760 - val_loss: 0.3427 - val_accuracy: 0.8556 - 2s/epoch - 4ms/step\n",
            "Epoch 3/40\n",
            "625/625 - 2s - loss: 0.2367 - accuracy: 0.9066 - val_loss: 0.3491 - val_accuracy: 0.8533 - 2s/epoch - 4ms/step\n",
            "Epoch 4/40\n",
            "625/625 - 2s - loss: 0.1902 - accuracy: 0.9280 - val_loss: 0.3634 - val_accuracy: 0.8483 - 2s/epoch - 4ms/step\n",
            "Epoch 5/40\n",
            "625/625 - 2s - loss: 0.1587 - accuracy: 0.9412 - val_loss: 0.3860 - val_accuracy: 0.8474 - 2s/epoch - 4ms/step\n",
            "Epoch 6/40\n",
            "625/625 - 2s - loss: 0.1336 - accuracy: 0.9533 - val_loss: 0.4340 - val_accuracy: 0.8353 - 2s/epoch - 3ms/step\n",
            "Epoch 7/40\n",
            "625/625 - 2s - loss: 0.1155 - accuracy: 0.9611 - val_loss: 0.4593 - val_accuracy: 0.8399 - 2s/epoch - 4ms/step\n",
            "Epoch 8/40\n",
            "625/625 - 2s - loss: 0.0990 - accuracy: 0.9661 - val_loss: 0.4921 - val_accuracy: 0.8381 - 2s/epoch - 4ms/step\n",
            "Epoch 9/40\n",
            "625/625 - 2s - loss: 0.0862 - accuracy: 0.9712 - val_loss: 0.5562 - val_accuracy: 0.8334 - 2s/epoch - 4ms/step\n",
            "Epoch 10/40\n",
            "625/625 - 2s - loss: 0.0753 - accuracy: 0.9762 - val_loss: 0.5787 - val_accuracy: 0.8313 - 2s/epoch - 4ms/step\n",
            "Epoch 11/40\n",
            "625/625 - 2s - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.6193 - val_accuracy: 0.8328 - 2s/epoch - 4ms/step\n",
            "Epoch 12/40\n",
            "625/625 - 2s - loss: 0.0568 - accuracy: 0.9827 - val_loss: 0.6735 - val_accuracy: 0.8280 - 2s/epoch - 4ms/step\n",
            "Epoch 13/40\n",
            "625/625 - 2s - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.7210 - val_accuracy: 0.8250 - 2s/epoch - 4ms/step\n",
            "Epoch 14/40\n",
            "625/625 - 2s - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.7785 - val_accuracy: 0.8222 - 2s/epoch - 4ms/step\n",
            "Epoch 15/40\n",
            "625/625 - 2s - loss: 0.0380 - accuracy: 0.9890 - val_loss: 0.8329 - val_accuracy: 0.8204 - 2s/epoch - 4ms/step\n",
            "Epoch 16/40\n",
            "625/625 - 2s - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.8742 - val_accuracy: 0.8179 - 2s/epoch - 4ms/step\n",
            "Epoch 17/40\n",
            "625/625 - 2s - loss: 0.0300 - accuracy: 0.9920 - val_loss: 0.9478 - val_accuracy: 0.8173 - 2s/epoch - 4ms/step\n",
            "Epoch 18/40\n",
            "625/625 - 2s - loss: 0.0282 - accuracy: 0.9919 - val_loss: 1.0022 - val_accuracy: 0.8168 - 2s/epoch - 4ms/step\n",
            "Epoch 19/40\n",
            "625/625 - 2s - loss: 0.0244 - accuracy: 0.9933 - val_loss: 1.0729 - val_accuracy: 0.8144 - 2s/epoch - 4ms/step\n",
            "Epoch 20/40\n",
            "625/625 - 2s - loss: 0.0210 - accuracy: 0.9941 - val_loss: 1.1220 - val_accuracy: 0.8110 - 2s/epoch - 4ms/step\n",
            "Epoch 21/40\n",
            "625/625 - 2s - loss: 0.0191 - accuracy: 0.9945 - val_loss: 1.2065 - val_accuracy: 0.8076 - 2s/epoch - 4ms/step\n",
            "Epoch 22/40\n",
            "625/625 - 2s - loss: 0.0173 - accuracy: 0.9952 - val_loss: 1.2538 - val_accuracy: 0.8061 - 2s/epoch - 4ms/step\n",
            "Epoch 23/40\n",
            "625/625 - 2s - loss: 0.0150 - accuracy: 0.9962 - val_loss: 1.3351 - val_accuracy: 0.8043 - 2s/epoch - 4ms/step\n",
            "Epoch 24/40\n",
            "625/625 - 2s - loss: 0.0136 - accuracy: 0.9965 - val_loss: 1.4034 - val_accuracy: 0.8059 - 2s/epoch - 4ms/step\n",
            "Epoch 25/40\n",
            "625/625 - 2s - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.4841 - val_accuracy: 0.8077 - 2s/epoch - 4ms/step\n",
            "Epoch 26/40\n",
            "625/625 - 2s - loss: 0.0111 - accuracy: 0.9969 - val_loss: 1.5228 - val_accuracy: 0.8047 - 2s/epoch - 4ms/step\n",
            "Epoch 27/40\n",
            "625/625 - 2s - loss: 0.0096 - accuracy: 0.9977 - val_loss: 1.5666 - val_accuracy: 0.8009 - 2s/epoch - 4ms/step\n",
            "Epoch 28/40\n",
            "625/625 - 2s - loss: 0.0096 - accuracy: 0.9973 - val_loss: 1.6145 - val_accuracy: 0.8012 - 2s/epoch - 4ms/step\n",
            "Epoch 29/40\n",
            "625/625 - 2s - loss: 0.0094 - accuracy: 0.9974 - val_loss: 1.6725 - val_accuracy: 0.8009 - 2s/epoch - 4ms/step\n",
            "Epoch 30/40\n",
            "625/625 - 2s - loss: 0.0081 - accuracy: 0.9974 - val_loss: 1.7412 - val_accuracy: 0.8024 - 2s/epoch - 4ms/step\n",
            "Epoch 31/40\n",
            "625/625 - 2s - loss: 0.0073 - accuracy: 0.9979 - val_loss: 1.7850 - val_accuracy: 0.7995 - 2s/epoch - 4ms/step\n",
            "Epoch 32/40\n",
            "625/625 - 2s - loss: 0.0060 - accuracy: 0.9984 - val_loss: 1.8907 - val_accuracy: 0.8006 - 2s/epoch - 4ms/step\n",
            "Epoch 33/40\n",
            "625/625 - 2s - loss: 0.0053 - accuracy: 0.9985 - val_loss: 1.9149 - val_accuracy: 0.7979 - 2s/epoch - 4ms/step\n",
            "Epoch 34/40\n",
            "625/625 - 2s - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.9682 - val_accuracy: 0.7983 - 2s/epoch - 4ms/step\n",
            "Epoch 35/40\n",
            "625/625 - 2s - loss: 0.0057 - accuracy: 0.9981 - val_loss: 2.0597 - val_accuracy: 0.8003 - 2s/epoch - 4ms/step\n",
            "Epoch 36/40\n",
            "625/625 - 2s - loss: 0.0044 - accuracy: 0.9988 - val_loss: 2.0653 - val_accuracy: 0.7980 - 2s/epoch - 4ms/step\n",
            "Epoch 37/40\n",
            "625/625 - 2s - loss: 0.0057 - accuracy: 0.9984 - val_loss: 2.1281 - val_accuracy: 0.7955 - 2s/epoch - 4ms/step\n",
            "Epoch 38/40\n",
            "625/625 - 2s - loss: 0.0050 - accuracy: 0.9984 - val_loss: 2.1981 - val_accuracy: 0.7994 - 2s/epoch - 4ms/step\n",
            "Epoch 39/40\n",
            "625/625 - 2s - loss: 0.0048 - accuracy: 0.9987 - val_loss: 2.3137 - val_accuracy: 0.7979 - 2s/epoch - 4ms/step\n",
            "Epoch 40/40\n",
            "625/625 - 2s - loss: 0.0036 - accuracy: 0.9988 - val_loss: 2.2676 - val_accuracy: 0.7955 - 2s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Clearly overfitting!!! ugh!!"
      ],
      "metadata": {
        "id": "4Wxhvsx2isyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}